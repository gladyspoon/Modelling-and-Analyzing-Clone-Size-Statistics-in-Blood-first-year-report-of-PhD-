{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the colors from colorbrewer2\n",
    "orange1 = '#feedde'\n",
    "orange2 = '#fdbe85'\n",
    "orange3 = '#fd8d3c'\n",
    "orange4 = '#e6550d'\n",
    "orange5 = '#a63603'\n",
    "blue1 = '#eff3ff'\n",
    "blue2 = '#bdd7e7'\n",
    "blue3 = '#6baed6'\n",
    "blue4 = '#3182bd'\n",
    "blue5 = '#08519c'\n",
    "green1 = '#edf8e9'\n",
    "green2 = '#bae4b3'\n",
    "green3 = '#74c476'\n",
    "green4 = '#31a354'\n",
    "green5 = '#006d2c'\n",
    "grey1 = '#f7f7f7'\n",
    "grey2 = '#cccccc'\n",
    "grey3 = '#969696'\n",
    "grey4 = '#636363'\n",
    "grey5 = '#252525'\n",
    "purple1 = '#f2f0f7'\n",
    "purple2 = '#cbc9e2'\n",
    "purple3 = '#9e9ac8'\n",
    "purple4 = '#756bb1'\n",
    "purple5 = '#54278f'\n",
    "red1 = '#fee5d9'\n",
    "red2 = '#fcae91'\n",
    "red3 = '#fb6a4a'\n",
    "red4 = '#de2d26'\n",
    "red5 = '#a50f15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of colors for plots\n",
    "c0 = (0.76, 0.76, 0.76)\n",
    "c1 = (1.00, 0.18, 0.33);\n",
    "c2 = (1.00, 0.23, 0.19);\n",
    "c3 = (1.00, 0.58, 0.00);\n",
    "c4 = (1.00, 0.80, 0.00);\n",
    "c5 = (0.30, 0.85, 0.39);\n",
    "c6 = (0.35, 0.78, 0.98);\n",
    "c7 = (0.20, 0.67, 0.86);\n",
    "c8 = (0.00, 0.48, 1.00);\n",
    "c9 = (0.35, 0.34, 0.84);\n",
    "c10 = (0.00, 0.31, 0.57);\n",
    "c11 = (0.12, 0.29, 0.69);\n",
    "c12 = (0.17, 0.17, 0.42);\n",
    "c13 = (1.00, 1.00, 1.00);\n",
    "c14 = (0.77, 0.04, 0.00);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported packages\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import matplotlib.ticker as plticker\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import cm\n",
    "import scipy.special\n",
    "import scipy.integrate as it\n",
    "from scipy import integrate\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import kde\n",
    "import copy\n",
    "import glob, os\n",
    "import re\n",
    "from sklearn import datasets, linear_model\n",
    "import pandas as pd\n",
    "from decimal import *\n",
    "from operator import itemgetter    \n",
    "from collections import OrderedDict\n",
    "import timeit\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All synonymous variants (in any gene)\n",
    "filename=\"Acuna_Hidalgo_2017_SNVs.csv\"\n",
    "with open(filename, 'r') as csvfile:\n",
    "    read_reader = csv.reader(csvfile)  #csv.reader returns a reader object which will iterate over lines in the csvfile\n",
    "    row_count=0\n",
    "    Acuna_synonymous_results={} \n",
    "    \n",
    "    for row in read_reader:\n",
    "        if row_count>0: #ignore the header of the CSV file\n",
    "            if row[8]=='synonymous': #only look at the synonymous variants (in any gene)\n",
    "#                 print(row)\n",
    "                VAF = row[2]\n",
    "                ID = row[7] #participant ID\n",
    "                age = float(row[0])\n",
    "                mutation_type = row[8] #synonymous\n",
    "                AA = row[6] #AA change, e.g. P9P\n",
    "                gene = row[1] #gene in which variant falls\n",
    "                Acuna_synonymous_results[row_count]=(ID, VAF, age, mutation_type, AA, gene)\n",
    "\n",
    "        row_count=row_count+1\n",
    "\n",
    "Acuna_synonymous = sorted(Acuna_synonymous_results.items(), key=lambda x: x[1][1], reverse=True)\n",
    "\n",
    "\n",
    "# All synonymous variants (in any gene)\n",
    "import csv\n",
    "filename=\"Young_2016_SNVs.csv\" #CSV file containing SNVs reported in Young 2016 and Young 2019 (only controls), but only includes 1 time-point (the earliest time-point at which a variant was detected in that individual)\n",
    "with open(filename, 'r') as csvfile:\n",
    "    read_reader = csv.reader(csvfile)  #csv.reader returns a reader object which will iterate over lines in the csvfile\n",
    "    row_count=0\n",
    "    Young2016_synonymous={}\n",
    "    \n",
    "    for row in read_reader:\n",
    "        if row[15]!='-': #only look at variants that were present in the individual's baseline samples\n",
    "            VAF = row[15] #In the csv file this is the average of the replicates at that time-point (VAFs that were '-' in original file were ignored)\n",
    "            ID = row[0] #participant ID\n",
    "            mutation_type = row[17] #whether the variant is missense or nonsense or synonymous\n",
    "            age = row[13]\n",
    "            AA = row[7] #AA change, e.g. P9P\n",
    "            if mutation_type == 'synonymous':\n",
    "                Young2016_synonymous[row_count]=(ID, VAF, mutation_type, AA, age)\n",
    "                        \n",
    "        row_count=row_count+1\n",
    "        \n",
    "Young2016_synonymous = sorted(Young2016_synonymous.items(), key=lambda x: x[1][1], reverse=True)\n",
    "\n",
    "\n",
    "# All synonymous variants (in any gene)\n",
    "import csv\n",
    "filename=\"Young_2019_SNVs.csv\" #CSV file containing SNVs reported in Young 2019 and Young 2019 (only controls), but only includes 1 time-point (the earliest time-point at which a variant was detected in that individual)\n",
    "with open(filename, 'r') as csvfile:\n",
    "    read_reader = csv.reader(csvfile)  #csv.reader returns a reader object which will iterate over lines in the csvfile\n",
    "    row_count=0\n",
    "    Young2019_synonymous={}\n",
    "    \n",
    "    for row in read_reader:\n",
    "        if row[2]!='case': #only look at the controls\n",
    "            if row[7]!='-': #only look at variants that were present in the individual's baseline samples\n",
    "                VAF = row[7] #In the csv file this is the average of the replicates at that time-point (VAFs that were '-' in original file were ignored)\n",
    "                ID = row[0] #participant ID\n",
    "                mutation_type = row[4] #whether the variant is missense or nonsense or synonymous\n",
    "                age = row[9]\n",
    "                AA = row[5] #AA change, e.g. P9P\n",
    "                if mutation_type == 'synonymous':\n",
    "                    Young2019_synonymous[row_count]=(ID, VAF, mutation_type, AA, age)\n",
    "\n",
    "        row_count=row_count+1\n",
    "        \n",
    "Young2019_synonymous = sorted(Young2019_synonymous.items(), key=lambda x: x[1][1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trimming synonymous variant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Young2016_synonymous_trimmed_list = []\n",
    "Young2019_synonymous_trimmed_list = []\n",
    "Young2016_2019_synonymous_trimmed_list = []\n",
    "Acuna_synonymous_trimmed_list = []\n",
    "\n",
    "Acuna_limit_log10 = -2.81029625 #previously -2.78675013\n",
    "Young2016_limit_log10 = -2.95376946\n",
    "Young2018_limit_log10 = -3.0617603\n",
    "\n",
    "Acuna_limit = 10**(Acuna_limit_log10) #previously -2.78675013\n",
    "Young2016_limit = 10**(Young2016_limit_log10) #previously -2.95376946\n",
    "Young2019_limit = 10**(Young2018_limit_log10)\n",
    "\n",
    "for (row_count,  VAF) in Acuna_synonymous:\n",
    "    if float(VAF[1])>=Acuna_limit:\n",
    "        Acuna_synonymous_trimmed_list.append(VAF[1])\n",
    "    \n",
    "for (ID,  VAF) in Young2016_synonymous:\n",
    "    if float(VAF[1])>=Young2016_limit:\n",
    "        Young2016_synonymous_trimmed_list.append(VAF[1])\n",
    "\n",
    "for (ID,  VAF) in Young2019_synonymous:\n",
    "    if float(VAF[1])>=Young2019_limit:\n",
    "        Young2019_synonymous_trimmed_list.append(VAF[1])\n",
    "\n",
    "# COMBINING YOUNG 2016 & 2019\n",
    "for (ID,  VAF) in Young2016_synonymous:\n",
    "    if float(VAF[1])>=Young2016_limit:\n",
    "        Young2016_2019_synonymous_trimmed_list.append(VAF[1])\n",
    "\n",
    "for (ID,  VAF) in Young2019_synonymous:\n",
    "    if float(VAF[1])>=Young2019_limit:\n",
    "        Young2016_2019_synonymous_trimmed_list.append(VAF[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize VAF densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalised_VAF_normalised_densities_list(trimmed_VAF_list, study_total, mu, binmethod):\n",
    "    y1 = []\n",
    "    for i in trimmed_VAF_list:\n",
    "        VAFs = float(i)\n",
    "        y = np.log(VAFs)\n",
    "        y1.append(y)\n",
    "        \n",
    "    normed_value = study_total*2*mu\n",
    "    hist, bins = np.histogram(y1, bins=binmethod, range=(min(y1),max(y1)))\n",
    "    widths = np.diff(bins)\n",
    "    bin_centres = (bins[:-1] + bins[1:])/2\n",
    "    hist = np.array(hist, dtype=float)\n",
    "    normalised_hist = hist/(normed_value*widths)\n",
    "    log_hist_for_plot = np.log(normalised_hist)\n",
    "\n",
    "    errors = error_bars(hist, normed_value, widths)\n",
    "    \n",
    "    VAF_densities=[]\n",
    "    lower_error = []\n",
    "    upper_error = []\n",
    "    for i in errors[0]:\n",
    "        lower_error.append(i)\n",
    "    for i in errors[1]:\n",
    "        upper_error.append(i)\n",
    "    VAF_densities_zip = zip(bin_centres, log_hist_for_plot, lower_error, upper_error)\n",
    "    for a, b, c, d in VAF_densities_zip:\n",
    "        VAF_densities.append((a, b, c, d))\n",
    "        \n",
    "    return VAF_densities\n",
    "\n",
    "def error_bars(hist, normed_value, widths):\n",
    "    \n",
    "    errors={}\n",
    "    n=0\n",
    "    for i in list(hist):\n",
    "        normalised_hist = i/(normed_value*widths)\n",
    "        log_hist = np.log(normalised_hist)\n",
    "        sqrt_hist = math.sqrt(i)\n",
    "        if sqrt_hist == 1:\n",
    "            upper_error = 1\n",
    "            lower_error = 0.9\n",
    "        if sqrt_hist !=1:\n",
    "            upper_error = sqrt_hist\n",
    "            lower_error = sqrt_hist\n",
    "        normalised_upper_error = upper_error/(normed_value*widths)\n",
    "        normalised_lower_error = lower_error/(normed_value*widths)\n",
    "        errors[n]=(normalised_hist[0], normalised_upper_error[0], normalised_lower_error[0])\n",
    "        n = n+1\n",
    "\n",
    "    errors_corrected ={}\n",
    "    for k, v in errors.items():\n",
    "        binheight = v[0]\n",
    "        log_binheight = np.log(v[0])\n",
    "        upper_error = v[1]\n",
    "        lower_error = v[2]\n",
    "        log_upper_error = (np.log(upper_error+binheight))-log_binheight\n",
    "        log_lower_error = log_binheight-(np.log(binheight-lower_error))\n",
    "        errors_corrected[k] = (log_binheight, log_upper_error, log_lower_error)\n",
    "\n",
    "    lower_err=[]\n",
    "    upper_err=[]\n",
    "    for k, v in errors_corrected.items():\n",
    "        lower_error = v[2]\n",
    "        upper_error = v[1]\n",
    "        lower_err.append(lower_error)\n",
    "        upper_err.append(upper_error)\n",
    "\n",
    "    err = [tuple(lower_err),tuple(upper_err)]\n",
    "    \n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chickchick\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in log\n",
      "  \n",
      "C:\\Users\\chickchick\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\chickchick\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\chickchick\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:56: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\chickchick\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:56: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\chickchick\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:57: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\chickchick\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:57: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "Youngtotal = 20\n",
    "Young2019totalcontrols = 69\n",
    "Acunatotal = 2006\n",
    "\n",
    "# Synonymous variants mutation rates\n",
    "Young_synonymous_mu = 7.60E-05\n",
    "Acuna_synonymous_mu = 2.68E-06\n",
    "\n",
    "binmethod = 'doane'\n",
    "young_synonymous_bins = 6\n",
    "\n",
    "Young_VAF_densities_neutral = normalised_VAF_normalised_densities_list(Young2016_2019_synonymous_trimmed_list, Youngtotal+Young2019totalcontrols, Young_synonymous_mu, young_synonymous_bins)\n",
    "Acuna_VAF_densities_neutral = normalised_VAF_normalised_densities_list(Acuna_synonymous_trimmed_list, Acunatotal, Acuna_synonymous_mu, binmethod)\n",
    "\n",
    "\n",
    "\n",
    "# Synonymous densities (normalised by 2 x mu)\n",
    "Neutral_densities = Young_VAF_densities_neutral+Acuna_VAF_densities_neutral\n",
    "\n",
    "Neutral_densities_without_inf = []    #remove the densities for the VAF bins for which there were no densities\n",
    "for i in Neutral_densities:\n",
    "    if i[1] != -(float('inf')):\n",
    "        Neutral_densities_without_inf.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 9.39358404e+04\n",
    "\n",
    "\n",
    "\n",
    "def mu_of_s(b, d, s, u, s_max): #mutation rate across an exponential distribution of s\n",
    "    s_peak = 0.0\n",
    "    weight_s= lambda s: np.exp(-((abs(s-s_peak))/d)**b)\n",
    "    normalization=integrate.quad(weight_s, 0.0, s_max)[0]\n",
    "    \n",
    "    return (u/normalization)*np.exp(-((abs(s))/d)**b)\n",
    "\n",
    "def expected_density_b_to_n_mutants_s_single(t, l, s1, b, d, mu_ben, s_max): #s1 = fitness of 1st mutation, s2 = fitness of 2nd mutation\n",
    "    combined_s=s1#sum of the fitness effects of the 2 mutations\n",
    "    mu1 = mu_of_s(b, d, s1, mu_ben, s_max) #mutation rate for 1st mutation with exponential distribution of s\n",
    "    mu2 = 1/2 #mutation rate for 2nd mutation with exponential distribution of s\n",
    "    n = (2*N*np.exp(l))/(1-2*np.exp(l))\n",
    "    psi = (np.exp(s1*t)-1)/s1\n",
    "    if n < psi:\n",
    "        expected_density = N*mu1*mu2*np.exp(l)/((2*N*np.exp(l)/(1-2*np.exp(l)))*s1+1)*\\\n",
    "        (np.exp(s1*t)/((2*N*np.exp(l)/(1-2*np.exp(l)))*s1+1)-1 +s1*t-np.log((2*N*np.exp(l)/(1-2*np.exp(l)))*s1+1)  )*(2*N/(1-2*np.exp(l))+4*N*np.exp(l)/(1-2*np.exp(l))**2)\n",
    "        \n",
    "    else:\n",
    "        expected_density = 0\n",
    "        \n",
    "    return (expected_density)\n",
    "\n",
    "\n",
    "def expected_number_b_to_n_mutants(t, l, b, d, mu_ben, s_max):\n",
    "    return integrate.quad(lambda s1: expected_density_b_to_n_mutants_s_single(t,  l, s1, b, d, mu_ben, s_max), 0, s_max)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expected_number_b_to_n_mutants' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dab61f455357>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexpected_number_b_to_n_mutants\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'expected_number_b_to_n_mutants' is not defined"
     ]
    }
   ],
   "source": [
    "result=expected_number_b_to_n_mutants(50, -3, b, d, 10**-5, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0020792662208927743"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.special\n",
    "import numpy as np\n",
    "import scipy.integrate as it\n",
    "from scipy import integrate\n",
    "b=0.33\n",
    "d=3.4e-4\n",
    "s_max=0.161\n",
    "mu=3.75e-5\n",
    "integrate.quad(lambda s1: mu_of_s(b, d, s1, mu, s_max), 0, s_max)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logProbtheory_ages_hitch(l, params): #= predicted density (i.e. normalised by 2 x mu)\n",
    "    \"Natural log of the probability of observing a variant within a specific binwidth if able to sequence perfectly\"\n",
    "    total_density=0.0\n",
    "    \n",
    "    #mu_ben=10**-5\n",
    "    b = params[0] # mutation rate of the beneficial mutations\n",
    "    d = params[1]\n",
    "    s_max = params[2]\n",
    "    mu_ben= params[3]\n",
    "    \n",
    "    \n",
    "    # FOR UNIFORM DISTIRIBUTION OF AGES + taking in to account neutral+ben and ben+neutral\n",
    "    total_density=integrate.quad(lambda t: expected_number_b_to_n_mutants(t, l, b, d, mu_ben, s_max), 20, 69)\n",
    "    \n",
    "    return np.log(total_density[0])        \n",
    "\n",
    "def logProbDataGivenModel_ages_hitch(params, data): #d = data (number of variants within a given bin), lamb (lambda) = expected number of variants in the bin from theory\n",
    "    \"This returns the natural log likelihood of the entire data, in specified binwidths, for a given theta and phi\"\n",
    "    total_square_distance = 0\n",
    "    for datapoint in data:\n",
    "        if np.exp(datapoint[0])>0.0025: #only look at data points with VAF >0.25%\n",
    "            logfreq = datapoint[0]\n",
    "            predicted_log_density = logProbtheory_ages_hitch(logfreq, params)\n",
    "            square_distance = ((datapoint[1] - predicted_log_density)**2)\n",
    "            total_square_distance = total_square_distance + square_distance\n",
    "\n",
    "    return total_square_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bounded three parameter b , d, s_max\n",
    "from scipy.optimize import Bounds\n",
    "bounds = Bounds([0, 0, 0], [1.0, 1.0, 1.0])\n",
    "initial_guess=[0.33, 0.00034204, 0.16122675]\n",
    "scipy.optimize.minimize(logProbDataGivenModel_ages_hitch, initial_guess,\\\n",
    "                        args=(Neutral_densities_without_inf,),  method='L-BFGS-B', bounds = bounds,options={'maxfev':1000000, 'maxiter':1000000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#five parameter b , d, s_max, mu_ben, mu_neu\n",
    "initial_guess=[0.33, 0.00034204, 0.16122675, 10**-5, 10**-5]\n",
    "scipy.optimize.minimize(logProbDataGivenModel_ages_hitch, initial_guess, args=(Neutral_densities_without_inf,), method='Nelder-Mead', options={'maxfev':1000000, 'maxiter':1000000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#four parameter b , d, s_max, mu_ben\n",
    "initial_guess=[0.33, 0.00034204, 0.16122675, 10**-5]\n",
    "scipy.optimize.minimize(logProbDataGivenModel_ages_hitch, initial_guess, args=(Neutral_densities_without_inf,), method='Nelder-Mead', options={'maxfev':1000000, 'maxiter':1000000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#three parameter b , d, s_max\n",
    "initial_guess=[0.33, 0.00034204, 0.16122675]\n",
    "scipy.optimize.minimize(logProbDataGivenModel_ages_hitch, initial_guess, args=(Neutral_densities_without_inf,), method='Nelder-Mead', options={'maxfev':1000000, 'maxiter':1000000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#store values of array before plotting colourmesh\n",
    "s_list = np.linspace(0.1, 0.2, 6)\n",
    "mu_ben_list = np.logspace(np.log10(10**(-7)), np.log10(10**(-3)), 5)\n",
    "logProbs_hitch = np.array([[logProbDataGivenModel_ages_hitch([2.27437637e-01, 3.48069520e-04, s, mu_ben], Neutral_densities_without_inf) for s in s_list] for mu_ben in mu_ben_list])\n",
    "np.savetxt('MLE_6x5_array_s_lin_10to20%_u_minus7_to_minus3.csv', logProbs_hitch, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('MLE_10x10_array_s_0to30%_u_minus10_to_minus3_test.csv', logProbs_hitch, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-05, 3.14382177e-05, 9.88361533e-05, 3.10723251e-04,\n",
       "       9.76858520e-04, 3.07106908e-03, 9.65489385e-03, 3.03532655e-02,\n",
       "       9.54252568e-02, 3.00000000e-01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_list = np.logspace(np.log10(0.12), np.log10(0.40), 2)\n",
    "mu_ben_list = np.logspace(np.log10(10**(-10)), np.log10(10**(-3)), 2)\n",
    "logProbs_hitch = np.array([[logProbDataGivenModel_ages_hitch([2.27437637e-01, 3.48069520e-04, s, mu_ben], Neutral_densities_without_inf) for s in s_list] for mu_ben in mu_ben_list])\n",
    "logProbs_hitch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLE colour map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the maximum likelihood estimates on a colormesh plot\n",
    "plt.close('all')\n",
    "#f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, sharex = True, figsize=(16, 7))\n",
    "f, ax1 = plt.subplots(1, 1, sharey=True, sharex = True, figsize=(16, 7))\n",
    "#gs = matplotlib.gridspec.GridSpec(1, 2, width_ratios=[1, 1], height_ratios=[1])\n",
    "ax1 = plt.subplot(gs[0])\n",
    "#ax2 = plt.subplot(gs[1])\n",
    "#gs.update(wspace=0.4)\n",
    "\n",
    "axisfont=17\n",
    "titlefont=20\n",
    "axislabelfont=21\n",
    "tpfont = 14\n",
    "m_size=8\n",
    "\n",
    "#VAFs\n",
    "#1 evaluation takes 2 minutes\n",
    "s_list = np.logspace(np.log10(0.12), np.log10(0.35), 20)\n",
    "mu_ben_list = np.logspace(np.log10(10**(-10)), np.log10(10**(-3)), 20)\n",
    "logProbs_hitch = np.array([[logProbDataGivenModel_ages_hitch([2.27437637e-01, 3.48069520e-04, s, mu_ben], Neutral_densities_without_inf) for s in s_list] for mu_ben in mu_ben_list])\n",
    "\n",
    "# Plot the density map using nearest-neighbor interpolation\n",
    "x1_hitch = s_list\n",
    "y1_hitch = mu_ben_list\n",
    "x1_hitch, y1_hitch = np.meshgrid(x1_hitch, y1_hitch)\n",
    "logProbs_hitch_s = (-logProbs_hitch)\n",
    "max_x, max_y = np.unravel_index(np.argmax(logProbs_hitch_s), logProbs_hitch_s.shape)\n",
    "z_max = logProbs_hitch_s[max_x, max_y]\n",
    "z1_hitch = np.exp(logProbs_hitch_s-(z_max))\n",
    "\n",
    "cmap = plt.cm.coolwarm #define colors\n",
    "\n",
    "ax1.pcolormesh(x1_hitch,y1_hitch,z1_hitch, cmap = cmap)\n",
    "\n",
    "#set labels\n",
    "ax1.set_title(\"Hitchhikers\", y = 1.05, fontsize = titlefont, fontweight='bold')\n",
    "ax1.set_xlabel('s', fontsize = axislabelfont)\n",
    "ax1.set_ylabel('beneficial mutation rate', fontsize = axislabelfont)\n",
    "#ax1.set_ylabel('\\u03BC beneficials', fontsize = axislabelfont)\n",
    "\n",
    "ax1.set_yscale('log')\n",
    "\n",
    "# calculate best values for mu (max points in 3D space (x,y,z))\n",
    "xmax, ymax = np.unravel_index(np.argmax(z1_hitch), z1_hitch.shape)\n",
    "uben_max = y1_hitch[xmax, ymax]\n",
    "s_max = x1_hitch[xmax, ymax]\n",
    "\n",
    "\n",
    "#ax1.scatter(s_max, uben_max, marker = '+', s = 1000, color = grey1, lw = 5)\n",
    "\n",
    "ax1.xaxis.set_tick_params(width=2, color = grey3, length = 6, labelsize = 16)\n",
    "ax1.yaxis.set_tick_params(width=2, color = grey3, length = 6, labelsize = 16)\n",
    "\n",
    "\n",
    "print('uben (ax1) = ', uben_max)\n",
    "print('s (ax1) =', s_max)\n",
    "\n",
    "#ax1.set_title('Hitchhikers', fontsize = 18)\n",
    "\n",
    "# ## Mu_ben vs S\n",
    "# logProbs_hitch = np.array([[logProbDataGivenModel_ages_hitch([2.27437637e-01, 3.48069520e-04, s, mu_ben], Neutral_densities_without_inf) for s in s_list] for mu_ben in mu_ben_list])\n",
    "\n",
    "# # Plot the density map using nearest-neighbor interpolation\n",
    "# x1_hitch_mu = mu_ben_list\n",
    "# y1_hitch_mu = s_list\n",
    "# x1_hitch_mu, y1_hitch_mu = np.meshgrid(x1_hitch_mu, y1_hitch_mu)\n",
    "# logProbs_hitch_mu = (-logProbs_hitch)\n",
    "# max_x_mu, max_y_mu = np.unravel_index(np.argmax(logProbs_hitch_mu), logProbs_hitch_mu.shape)\n",
    "# z_max_mu = logProbs_hitch_mu[max_x_mu, max_y_mu]\n",
    "# z1_hitch_mu = np.exp(logProbs_hitch_mu-(z_max_mu))\n",
    "\n",
    "# cmap = plt.cm.coolwarm #define colors\n",
    "\n",
    "# ax2.pcolormesh(x1_hitch_mu,y1_hitch_mu,z1_hitch_mu, cmap = cmap)\n",
    "\n",
    "# #set labels\n",
    "# ax2.set_xlabel('mu_ben', fontsize = axislabelfont)\n",
    "# ax2.set_ylabel('s(%)', fontsize = axislabelfont)\n",
    "\n",
    "# ax2.set_xscale('log')\n",
    "\n",
    "# # calculate best values (max points in 3D space (x,y,z))\n",
    "# xmax_mu, ymax_mu = np.unravel_index(np.argmax(z1_hitch_mu), z1_hitch_mu.shape)\n",
    "# s_max = y1_hitch_mu[xmax_mu, ymax_mu]\n",
    "# max_mu = x1_hitch_mu[xmax_mu, ymax_mu]\n",
    "# z_max = z1_hitch_mu[xmax_mu, ymax_mu]\n",
    "\n",
    "# ax2.xaxis.set_tick_params(width=2, color = grey3, length = 6, labelsize = 16)\n",
    "# ax2.yaxis.set_tick_params(width=2, color = grey3, length = 6, labelsize = 16)\n",
    "\n",
    "# ax2.scatter(max_mu, s_max, marker = '+', s = 1000, color = grey1, lw = 5)\n",
    "\n",
    "# print('')\n",
    "# print('mu_ben (ax2) = ', max_mu)\n",
    "# print('s (ax2) =', s_max)\n",
    "plt.savefig('MLE_20x20.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.savefig('MLE_20x20.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot MLE histrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_log_hist_data_for_plot_solid_smaller(study_VAFs, study_total, study_mu, bin_size, study_name, marker_name, marker_size, color):\n",
    "    #for plotting graphs that will not span the full width of the page and so will need larger markers\n",
    "    log_VAFs = []\n",
    "    for i in study_VAFs:\n",
    "        log_VAFs.append(np.log(float(i)))\n",
    "    normed_value = study_total*2*study_mu\n",
    "#     bin_size = int((max(log_VAFs)-min(log_VAFs))/(1/((len(log_VAFs))**(1/3))))\n",
    "    hist, bins = np.histogram(log_VAFs, bins=bin_size, range=(min(log_VAFs),max(log_VAFs)))\n",
    "    widths = np.diff(bins)\n",
    "    bin_centres = (bins[:-1] + bins[1:])/2\n",
    "    hist = np.array(hist, dtype=float)\n",
    "    normalised_hist = hist/(normed_value*widths)\n",
    "    log_hist_for_plot = np.log(normalised_hist)\n",
    "    \n",
    "    errors = error_bars(hist, normed_value, widths)\n",
    "    \n",
    "    axisfont=14*scale\n",
    "    axislabelfont=15*scale\n",
    "    tpfont = 14*scale\n",
    "\n",
    "    m_size = 18*scale\n",
    "    m_width = 1.5*scale\n",
    "    c_size = 3*scale\n",
    "    c_thick = 1.5*scale\n",
    "    e_width = 1.5*scale\n",
    "\n",
    "    Jaiswalmarker = 'o'\n",
    "    Zinkmarker = '^'\n",
    "    Acunamarker = 'P'\n",
    "    Coombsmarker = 'v'\n",
    "    Youngmarker = 'p'\n",
    "    Mckerrelmarker = 'D'\n",
    "    Genovesemarker = 'd'\n",
    "    Desaimarker = '*'\n",
    "    Abelsonmarker = '>'\n",
    "\n",
    "    #Colors\n",
    "    DNMT3A_color = 'dodgerblue'\n",
    "    R882_color = c1\n",
    "    neutralcolor = c3\n",
    "    \n",
    "    #Plot\n",
    "    ax1.errorbar(bin_centres, log_hist_for_plot, yerr= errors, fmt = marker_name, ecolor = color, \\\n",
    "             elinewidth = e_width, capsize = c_size, capthick = c_thick, markersize = marker_size, markeredgewidth = m_width, \\\n",
    "             markeredgecolor = color, markerfacecolor = color, label = study_name, zorder=0)\n",
    "    \n",
    "    # Set axis limits\n",
    "    ax1.set_ylim(1, 14)\n",
    "    ax1.set_xlim(-9, 0)\n",
    "    # ax1.set_xlim(-7.6, 0)\n",
    "\n",
    "    # Axis labels\n",
    "    ax1.set_xlabel('variant allele frequency (%)', fontsize = axislabelfont, labelpad = 6*scale, fontweight = 'medium')\n",
    "    ax1.set_ylabel('relative density of variants', fontsize = axislabelfont, labelpad = 6*scale, fontweight = 'medium')\n",
    "\n",
    "    x_major_ticks = [np.log(0.0001),np.log(0.0002),np.log(0.0003),np.log(0.0004),np.log(0.0005),np.log(0.0006),np.log(0.0007),np.log(0.0008), np.log(0.0009),\\\n",
    "                     np.log(0.001), np.log(0.002),np.log(0.003),np.log(0.004),np.log(0.005),np.log(0.006),np.log(0.007),np.log(0.008),np.log(0.009), \\\n",
    "                     np.log(0.01),np.log(0.02),np.log(0.03),np.log(0.04),np.log(0.05),np.log(0.06),np.log(0.07),np.log(0.08),np.log(0.09),\\\n",
    "                     np.log(0.1),np.log(0.2),np.log(0.3),np.log(0.4),np.log(0.5),np.log(0.6),np.log(0.7),np.log(0.8),np.log(0.9), np.log(1.0)]\n",
    "    x_major_tick_labels = [\"0.01\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\\\n",
    "                           \"0.1\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\\\n",
    "                           \"1\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\\\n",
    "                           \"10\",\"\",\"\",\"\",\"50\",\"\",\"\",\"\",\"\",\"\"]\n",
    "    ax1.set_xticks(x_major_ticks)\n",
    "    ax1.set_xticklabels(x_major_tick_labels, fontsize = axisfont)\n",
    "    ax1.xaxis.set_tick_params(width=scale, color = grey3, length = 6)\n",
    "\n",
    "    y_major_ticks = [np.log(1), np.log(2), np.log(3), \\\n",
    "                     np.log(4), np.log(5), np.log(6), \\\n",
    "                     np.log(7), np.log(8), np.log(9), \\\n",
    "                     np.log(10), np.log(20), np.log(30),\\\n",
    "                     np.log(40), np.log(50), np.log(60), \\\n",
    "                     np.log(70), np.log(80), np.log(90),\\\n",
    "                     np.log(100), np.log(200), np.log(300), \\\n",
    "                     np.log(400), np.log(500), np.log(600),\\\n",
    "                     np.log(700), np.log(800), np.log(900), \\\n",
    "                     np.log(1000), np.log(2000), np.log(3000),\\\n",
    "                    np.log(4000), np.log(5000), np.log(6000), \\\n",
    "                     np.log(7000), np.log(8000), np.log(9000),\\\n",
    "                    np.log(10000), np.log(20000), np.log(30000), \\\n",
    "                     np.log(40000), np.log(50000), np.log(60000),\\\n",
    "                    np.log(70000), np.log(80000), np.log(90000), \\\n",
    "                     np.log(100000), np.log(200000),np.log(300000),np.log(400000),np.log(500000),np.log(600000),\\\n",
    "                    np.log(700000),np.log(800000),np.log(900000),np.log(1000000)]\n",
    "    y_major_tick_labels = [\"\",\"\",\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"$10^{1}$\",\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \\\n",
    "                           \"$10^{2}$\",\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"$10^{3}$\",\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \\\n",
    "                           \"$10^{4}$\",\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"$10^{5}$\",\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"$10^{6}$\"]\n",
    "    ax1.set_yticks(y_major_ticks)\n",
    "    ax1.set_yticklabels(y_major_tick_labels, fontsize = axisfont)\n",
    "    ax1.yaxis.set_tick_params(width=scale, color = grey3, length = 6)\n",
    "\n",
    "    #Only show the required axis lines\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "\n",
    "    for axis in ['bottom','left']:\n",
    "        ax1.spines[axis].set_linewidth(1.5)\n",
    "\n",
    "    for axis in ['bottom','left']:\n",
    "        ax1.spines[axis].set_color(grey3)\n",
    "        \n",
    "    \n",
    "#     #set panel legends\n",
    "#     legend_marker_size = 8*scale\n",
    "#     legend_elements = [Line2D([0], [0], marker = Jaiswalmarker, color = grey3, alpha = 0.4, markersize = legend_marker_size*1.1, \\\n",
    "#                               lw=0, label='Jaiswal 2014'),\n",
    "#                        Line2D([0], [0], marker = Genovesemarker, color=grey3, alpha=0.4, markersize = legend_marker_size*1.1, \\\n",
    "#                               lw=0, label='Genovese 2014'),\n",
    "#                        Line2D([0], [0], marker = Mckerrelmarker, color=grey3, alpha=0.4, markersize = legend_marker_size, \\\n",
    "#                               lw=0, label='McKerrel 2015'),\n",
    "#                        Line2D([0], [0], marker = Zinkmarker, color=grey3, alpha=0.4, markersize = legend_marker_size*1.2, \\\n",
    "#                               lw=0, label='Zink 2017'),\n",
    "#                       Line2D([0], [0], marker = Acunamarker, color=grey3, alpha=0.4, markersize = legend_marker_size*1.3, \\\n",
    "#                               lw=0, label='Acuna-Hidalgo 2017'),\n",
    "#                       Line2D([0], [0], marker = Coombsmarker, color=grey3, alpha=0.4, markersize = legend_marker_size*1.2, \\\n",
    "#                               lw=0, label='Coombs 2017'),\n",
    "#                       Line2D([0], [0], marker = Youngmarker, color=grey3, alpha=0.4, markersize = legend_marker_size*1.2, \\\n",
    "#                               lw=0, label='Young 2016 & 2019'),\n",
    "#                        Line2D([0], [0], marker = Desaimarker, color=grey3, alpha=0.4, markersize = legend_marker_size*1.5, \\\n",
    "#                               lw=0, label='Desai 2018'),]\n",
    "\n",
    "#     ax1.legend(ncol=1, handles=legend_elements, loc='center', bbox_to_anchor=(0.16, 0.2), frameon=0, fontsize = 16*scale)\n",
    "    \n",
    "    return ax1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the histogram\n",
    "plt.close('all')\n",
    "scale = 1.2\n",
    "f, (ax1) = plt.subplots(1, 1, sharey=True, figsize=(12*scale, 8*scale))\n",
    "\n",
    "Acunamarker = 'P' #plus sign\n",
    "Youngmarker = 'p' #pentagon\n",
    "\n",
    "neutralcolor=c3\n",
    "\n",
    "m_size = 14\n",
    "Jaiswalmarkersize = m_size*1.1\n",
    "Genovesemarkersize = m_size*1.1\n",
    "Zinkmarkersize = m_size*1.2\n",
    "Acunamarkersize = m_size*1.3\n",
    "Coombsmarkersize = m_size*1.2\n",
    "Youngmarkersize = m_size*1.2\n",
    "Desaimarkersize = m_size*1.5\n",
    "McKerrelmarkersize = m_size*1\n",
    "Liumarkersize = m_size*1\n",
    "\n",
    "#Synoymous variants (all genes)\n",
    "plot_log_hist_data_for_plot_solid_smaller(Acuna_synonymous_trimmed_list, Acunatotal, Acuna_synonymous_mu, binmethod, \\\n",
    "                            'Acuna-Hidalgo 2017', Acunamarker, Acunamarkersize, neutralcolor)\n",
    "plot_log_hist_data_for_plot_solid_smaller(Young2016_2019_synonymous_trimmed_list, Young2019totalcontrols+Youngtotal, Young_synonymous_mu, young_synonymous_bins, \\\n",
    "                            'Young 2016 & 2019', Youngmarker, Youngmarkersize, neutralcolor)\n",
    "\n",
    "#Hitchhiker theory line with MLE values (including only synonymous variants with VAF >0.25%)\n",
    "mu_ben =  2.681812609453013e-06\n",
    "s = 0.19061965125701302\n",
    "\n",
    "x=np.linspace(-10, -0.7, 1000)\n",
    "y=[logProbtheory_ages_hitch(l, [s, mu_ben]) for l in x]\n",
    "ax1.plot(x, y, c = neutralcolor, lw = 4, alpha = 0.75, linestyle = '--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
